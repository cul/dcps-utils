# Script to log results from other scripts to a sheet
# and report results based on date to email notification.
# Call post_digest() from other scripts to add to log.
# Call main() to generate report.

from sheetFeeder import dataSheet
import datetime
import dateutil.parser
from itertools import groupby
from pprint import pprint
import os


digest_sheet_id = "190p6gnhpakdYD72Eb1PLicdVlAtAxjQ7D_8oee7Tk1U"
digest_sheet_id2 = "1PLtSL1NHQ_PooSd2LkEDTHZMmhmrxPv4cv8STpmhknk"  # test
digest_range = "Sheet1!A:Z"

digest_sheet = dataSheet(digest_sheet_id, digest_range)
digest_sheet2 = dataSheet(digest_sheet_id2, digest_range)  # test

MY_NAME = __file__
SCRIPT_NAME = os.path.basename(MY_NAME)
# This makes sure the script can be run from any working directory and still find related files.

NOW = str(datetime.datetime.now().strftime("%m/%d/%Y %H:%M:%S"))
TODAY = datetime.datetime.today()
# GARBAGE_DAY = 1
GARBAGE_DAY = 21  # test
MONTH_OFFSET = 2
DATE_COLUMN = 1


def main():
    """Script to log results from other scripts to a sheet
    and report results based on date to email notification.
    Relies on a Google Sheet with log data.
    Call post_digest() from other scripts to add to log.
    Call main() to generate report, e.g., for daily digest email.
    Set GARBAGE_DAY to day of month on which to perform cleanup.
    """

    FIXTURE_SHEET = dataSheet(
        "1PLtSL1NHQ_PooSd2LkEDTHZMmhmrxPv4cv8STpmhknk", "fixture!A:Z"
    )
    FIXTURE_DATA = FIXTURE_SHEET.getData()
    TEST_DATE = dateutil.parser.parse("2021-09-1")

    l1 = len(FIXTURE_DATA)
    l2 = len(prune_data(FIXTURE_DATA, 1, TEST_DATE))
    print(l1)
    print(l2)
    print(l2 < l1 and l2 == 37)

    new_digest = get_digest(FIXTURE_SHEET)
    print(get_digest(FIXTURE_SHEET))
    print(len(new_digest))

    print(date_is_recent(TEST_DATE))
    quit()

    if TODAY.day == GARBAGE_DAY:
        print("Cleaning up old digest entries...")
        x = cleanup_datasheet(digest_sheet)
        print(" ")

    icons = {
        "right-triangle": "\U000025B6",
    }

    print(
        "This 24-hour digest composed at "
        + NOW
        + " by "
        + SCRIPT_NAME
        + ". Contact asops@library.columbia.edu with questions/problems."
    )

    print(" ")
    print(" ")

    # Format the digest content.
    for s in get_digest():
        print(icons["right-triangle"] + " *** OUTPUT FROM " + s["script"] + " ***")
        for m in s["msg"]:
            print("â€¢ " + m["value"])
        print("******************")
        print(" ")

    # print('This 24-hour digest generated by ' + script_name + ' on ' +
    #       datetime.datetime.now().strftime('%m/%d/%Y %H:%M:%S') + '.')


def date_is_recent(_date, _offset=1):
    """Check if input date is within 24 hours (or other day offset value) of current time.

    Args:
        _date (datetime date): A date to compare  (datetime object)
        _offset (int, optional): Number of days to consider recent. Defaults to 1.

    Returns:
        bool: Boolean
    """
    d_compare = datetime.datetime.now() - datetime.timedelta(days=_offset)
    return _date > d_compare


def get_digest(sheet=digest_sheet):
    """Get digest-formatted output from log dataSheet.

    Args:
        sheet (dataSheet, optional): dataSheet with log data. Defaults to digest_sheet.

    Returns:
        list: List of log entries, aggregated daily by script name
    """
    data = sheet.getData()
    # heads = data.pop(0)
    the_msg_data = []
    for a_row in data:
        name = a_row[0]
        # date = datetime.datetime.strptime(a_row[1], "%m/%d/%Y %H:%M:%S")
        date = dateutil.parser.parse(a_row[1]).strftime("%m/%d/%Y %H:%M:%S")
        date = dateutil.parser.parse(a_row[1])
        msg = a_row[2]
        if date_is_recent(date):
            # if date == datetime.today().date():
            the_msg_data.append([name, date, msg])

    # the_msg_data.sort(key=lambda x: x[1], reverse=True)
    # TODO: Sort output reverse chronologically.

    # use itertools.groupby to compose results into lists of messages grouped by script name.
    the_result = []
    for key, group in groupby(sorted(the_msg_data), lambda x: x[0]):

        # Return a dict of values with timestamps grouped by script.
        r = {"script": key, "msg": [{"time": m[1], "value": m[2]} for m in group]}

        the_result.append(r)
        # Sort the results reverse chronologically.
        the_result.sort(key=lambda x: x["msg"][0]["time"], reverse=True)

    return the_result


def digest_clear(sheet=digest_sheet):
    return sheet.clear()


def post_digest(script_name, log, sheet=digest_sheet, truncate=40000):
    """Add a digest record to log sheet.

    Args:
        script_name (str): filename of generating script
        log (str): Log text
        sheet (dataSheet, optional): sheetFeeder dataSheet. Defaults to digest_sheet.
        truncate (int, optional): Max length of log entry. Defaults to 40000.

    Returns:
        str: JSON response of POST to sheet.
    """
    date = str(datetime.datetime.today())
    if len(log) > truncate:
        log = log[:truncate] + "[...]"
    data = [[script_name, date, log]]
    return sheet.appendData(data)


def prune_data(array, date_column, compare_date, month_offset=2):
    """Filter array (list of lists) to rows with recent dates.
    By default, remove all rows except from current and previous month.

    Args:
        array (list): 2D array (list of lists)
        date_column (int): Column index where date is found
        compare_date (datetime date): Date from which to obtain current month
        month_offset (int, optional): Number of months to include. Defaults to 2.

    Returns:
        list: 2D array (list of lists)
    """
    new_array = []
    for row in array:
        date = dateutil.parser.parse(row[date_column])
        if date.month > (compare_date.month - month_offset):
            new_array.append(row)
    return new_array


def cleanup_datasheet(data_sheet, date_column=DATE_COLUMN, month_offset=MONTH_OFFSET):
    """Prune log sheet to recent entries (by month)

    Args:
        data_sheet (dataSheet): Sheet with log data to clean up
        date_column (int, optional): Col index where date is found. Defaults to DATE_COLUMN.
        month_offset (int, optional): Number of months to include. Defaults to MONTH_OFFSET.

    Returns:
        str: JSON response
    """
    data = data_sheet.getData()
    new_data = prune_data(data, 1, TODAY)
    if len(new_data) > 0:
        print(
            str(len(data) - len(new_data))
            + " removed. "
            + str(len(new_data))
            + " recent entries retained."
        )
        data_sheet.clear()
        return data_sheet.appendData(new_data)


if __name__ == "__main__":
    main()
